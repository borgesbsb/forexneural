{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing:\n",
    "    def __init__(self, filedataset, begining_training, end_training,end_testing, timestamp, features, target):\n",
    "        self.timestamp = timestamp\n",
    "        self.features  = features\n",
    "        self.begining_training = begining_training\n",
    "        self.end_training = end_training\n",
    "        self.end_testing = end_testing\n",
    "        self.df  = self.importDataset()\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        self.x_test  = []\n",
    "        self.y_test  = []\n",
    "        self.scaler_x = None\n",
    "        self.scaler_y = None\n",
    "        self.target = target\n",
    "        self.df_training =  None\n",
    "        self.df_test = None\n",
    "        self.splitData()\n",
    "    \n",
    "    def importDataset(self):\n",
    "        parser = lambda x: pd.datetime.strptime(x, \"%Y.%m.%d %H:%M:%S\")\n",
    "        df = pd.read_csv( filedataset, sep=';', header=0, parse_dates=['time'],date_parser=parser) \n",
    "        return df\n",
    "    \n",
    "    def selectInterval(self, start, end):\n",
    "        mask = (self.df['time'] > start) & (self.df['time'] <= end )\n",
    "        return self.df.loc[mask]\n",
    "    \n",
    "    def scalerDataset(self, dataset):\n",
    "        self.scaler_x = MinMaxScaler()\n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        self.scaler_x.fit(dataset)\n",
    "        self.scaler_y.fit(self.df[[target]])\n",
    "        return self.scaler_x.transform(dataset)\n",
    "\n",
    "    def processXY(self, dataframe):\n",
    "        length = len(dataframe)\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for i in range(self.timestamp, length):\n",
    "            x_data.append( dataframe[i-self.timestamp:i,:])\n",
    "            y_data.append( dataframe[i,self.features.index(target)])\n",
    "        x_data = np.array(x_data)\n",
    "        y_data = np.array(y_data)\n",
    "        x_data = np.reshape(x_data, (x_data.shape[0], self.timestamp, len(features)))\n",
    "        return x_data, y_data\n",
    "     \n",
    "    def splitData(self):\n",
    "        #Selecionando Intervalos de datas para treino\n",
    "        self.df_training = self.selectInterval(self.begining_training, self.end_training)\n",
    "        #selecionando colunas para treino\n",
    "        self.df_training = self.df_training[self.features]\n",
    "        #Escalando o dataset de treino usando a funcao MinMax()\n",
    "        self.x_train = self.scalerDataset(self.df_training)\n",
    "        #Processando o dataset com o shape adequado para a modelagem \n",
    "        self.x_train, self.y_train = self.processXY( self.x_train )\n",
    "        #Selecionando Intervalos de datas para teste\n",
    "        self.df_test = self.selectInterval(self.end_training, self.end_testing)\n",
    "        #selecionando colunas do dataset para teste\n",
    "        self.x_test = self.df_test[self.features]\n",
    "        #Escalando o dataset de treino\n",
    "        self.x_test = self.scaler_x.transform(self.x_test)\n",
    "        #Processando o dataset com o shape adequado para a modelagem \n",
    "        self.x_test , self.y_test  = self.processXY( self.x_test )\n",
    "\n",
    "\n",
    "#########################Fim da classe de processamento############################################################\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, ds, neurons, timestamp, features, epochs):\n",
    "        self.model = None\n",
    "        self.ds = ds\n",
    "        self.neurons = neurons\n",
    "        self.timestamp = timestamp\n",
    "        self.features = features\n",
    "        self.epochs = epochs\n",
    "        self.trainingLSTM()\n",
    "        \n",
    "    def configuringLSTM(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(units = self.neurons, return_sequences = False, input_shape=( self.timestamp , len(self.features) ) ))\n",
    "        # self.model.add(Dropout(0.01))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    def trainingLSTM(self):\n",
    "        self.configuringLSTM()\n",
    "        self.model.fit(self.ds.x_train, self.ds.y_train, epochs = self.epochs)\n",
    "        self.model.save('LSTM_GBPUSD')\n",
    "\n",
    "#########################Fim da classe de Treinamento#############################################################\n",
    "\n",
    "class Testing:\n",
    "    def __init__(self, modelTraining, ds ):\n",
    "        self.modelTraining  = modelTraining\n",
    "        self.ds     = ds\n",
    "        self.y_pred = []\n",
    "        self.predictedPrice = []\n",
    "        self.prevision = None\n",
    "        self.time = None\n",
    "        self.max = None\n",
    "        self.min = None\n",
    "        self.result_to_csv = None\n",
    "        self.predicting()\n",
    "        self.estatistical()\n",
    "    \n",
    "    def predicting(self):\n",
    "        self.predictedPrice =  self.modelTraining.model.predict(self.ds.x_test) \n",
    "        self.predictedPrice =  self.ds.scaler_y.inverse_transform(self.predictedPrice)\n",
    "    \n",
    "    def estatistical(self):\n",
    "        self.prevision = pd.DataFrame(data=self.predictedPrice, columns=['Previsão'])\n",
    "        self.time      = pd.DataFrame(data=self.ds.df_test['time'].shift(-self.ds.timestamp).dropna().values, columns=['Data'])\n",
    "        self.maxima    = pd.DataFrame(data=self.ds.df_test['low1'].shift(-self.ds.timestamp).dropna().values, columns=['Máxima'])\n",
    "        self.minima    = pd.DataFrame(data=self.ds.df_test['high1'].shift(-self.ds.timestamp).dropna().values, columns=['Minima'])\n",
    "        frames_to_csv= [ self.time, self.maxima, self.minima, self.prevision ]\n",
    "        self.result_to_csv = pd.concat( frames_to_csv, axis=1, join='inner')\n",
    "        \n",
    "    def saveToCsv(self):\n",
    "        self.result_to_csv.to_csv('previsoes.csv', mode='a', header=False,index=False)\n",
    "      \n",
    "    def graphicMaxMin(self, window):\n",
    "        y_test = []\n",
    "        y_test = self.ds.df_test['close1'].shift(-self.ds.timestamp).dropna()\n",
    "        plt.plot(y_test[:window], color='red', label='Preço Atual das Ações')\n",
    "        plt.plot(y_test.index.values[:window], self.prevision.iloc[:window,0] , '.')\n",
    "        plt.fill_between(y_test.index.values[:window], self.maxima.iloc[:window,0], self.minima.iloc[:window,0], alpha=0.5)\n",
    "        plt.title('Previsão de Preço de Ações')\n",
    "        plt.xlabel('Tempo')\n",
    "        plt.ylabel('Preço das Ações')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(self.modelTraining.model.evaluate(self.ds.x_test, y_test, verbose=0)*100)\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1162/1162 [==============================] - 18s 16ms/step - loss: 0.0098\n",
      "Epoch 2/30\n",
      "1162/1162 [==============================] - 18s 16ms/step - loss: 0.0034\n",
      "Epoch 3/30\n",
      "1162/1162 [==============================] - 18s 16ms/step - loss: 0.0034\n",
      "Epoch 4/30\n",
      "1162/1162 [==============================] - 18s 15ms/step - loss: 0.0032\n",
      "Epoch 5/30\n",
      "1162/1162 [==============================] - 18s 16ms/step - loss: 0.0033\n",
      "Epoch 6/30\n",
      "1162/1162 [==============================] - 17s 15ms/step - loss: 0.0033\n",
      "Epoch 7/30\n",
      "1162/1162 [==============================] - 17s 14ms/step - loss: 0.0031\n",
      "Epoch 8/30\n",
      "1162/1162 [==============================] - 17s 15ms/step - loss: 0.0030\n",
      "Epoch 9/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0031\n",
      "Epoch 10/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0030\n",
      "Epoch 11/30\n",
      "1162/1162 [==============================] - 16s 14ms/step - loss: 0.0030\n",
      "Epoch 12/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0029\n",
      "Epoch 13/30\n",
      "1162/1162 [==============================] - 19s 17ms/step - loss: 0.0030\n",
      "Epoch 14/30\n",
      "1162/1162 [==============================] - 17s 15ms/step - loss: 0.0029\n",
      "Epoch 15/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0029\n",
      "Epoch 16/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0028\n",
      "Epoch 17/30\n",
      "1162/1162 [==============================] - 19s 17ms/step - loss: 0.0028\n",
      "Epoch 18/30\n",
      "1162/1162 [==============================] - 18s 16ms/step - loss: 0.0028\n",
      "Epoch 19/30\n",
      "1162/1162 [==============================] - 18s 15ms/step - loss: 0.0028\n",
      "Epoch 20/30\n",
      "1162/1162 [==============================] - 17s 15ms/step - loss: 0.0028\n",
      "Epoch 21/30\n",
      "1162/1162 [==============================] - 18s 15ms/step - loss: 0.0027\n",
      "Epoch 22/30\n",
      "1162/1162 [==============================] - 17s 15ms/step - loss: 0.0026\n",
      "Epoch 23/30\n",
      "1162/1162 [==============================] - 18s 15ms/step - loss: 0.0026\n",
      "Epoch 24/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0027\n",
      "Epoch 25/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0027\n",
      "Epoch 26/30\n",
      "1162/1162 [==============================] - 19s 17ms/step - loss: 0.0027\n",
      "Epoch 27/30\n",
      "1162/1162 [==============================] - 18s 15ms/step - loss: 0.0026\n",
      "Epoch 28/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0026\n",
      "Epoch 29/30\n",
      "1162/1162 [==============================] - 19s 16ms/step - loss: 0.0026\n",
      "Epoch 30/30\n",
      "1162/1162 [==============================] - 20s 17ms/step - loss: 0.0026\n",
      "WARNING:tensorflow:From /home/borgesbsb/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: LSTM_GBPUSD/assets\n"
     ]
    }
   ],
   "source": [
    "begining_training = '2012-01-04'\n",
    "\n",
    "end_training = '2018-01-01 00:00:00'\n",
    "\n",
    "end_test = '2019-01-01 00:00:00'\n",
    "\n",
    "filedataset  = 'GBPUSD.csv'\n",
    "\n",
    "features = ['open1','high1','low1','close1']\n",
    "\n",
    "target   = 'close1'\n",
    "\n",
    "timestamp = 2\n",
    "\n",
    "neurons = 120\n",
    "\n",
    "epochs  = 30\n",
    "\n",
    "datasetProcessed = Processing( filedataset, begining_training, end_training, end_test, timestamp, features, target  )\n",
    "\n",
    "modelTrained = Training( datasetProcessed, neurons, timestamp, features, epochs )\n",
    "\n",
    "estatisticalTested  = Testing( modelTrained, datasetProcessed )\n"
   ]
  }
 ]
}