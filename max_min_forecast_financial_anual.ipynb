{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "max_min_forecast_financial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlHfEgltlXZN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as plt \n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20, 4\n",
        "import tensorflow as tf\n",
        "periodo_aprendizado = '2018-01-05 21:00:00' #periodo incrementado\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTUVaC3QxFvr"
      },
      "source": [
        "start_date = '2012-01-01'\n",
        "parser = lambda x: pd.datetime.strptime(x, \"%Y.%m.%d %H:%M:%S\")\n",
        "df = pd.read_csv('EURUSD.csv', sep=',', header=0,parse_dates=['time'],date_parser=parser)\n",
        "avanco_da_rede = 6099\n",
        "indice_total_treino = 0\n",
        "\n",
        "\n",
        "features = 4\n",
        "timestamp = 2\n",
        "epochs = 50\n",
        "janela = 7\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_train = None\n",
        "y_train = None\n",
        "\n",
        "mask = (df['time'] > start_date) & (df['time'] <= periodo_aprendizado )\n",
        "df_train = df.loc[mask]\n",
        "df_train_orig_2 = df_train.iloc[:,0:5]\n",
        "df_train = df_train.iloc[:,1:5]\n",
        "df_train_orig = df_train.copy()\n",
        "# print(df_train)\n",
        "\n",
        "indice_total_treino = len(df_train)\n",
        "\n",
        "df_test      = df.iloc[ indice_total_treino:indice_total_treino+avanco_da_rede,1:5]\n",
        "df_test_orig = df.iloc[ indice_total_treino:indice_total_treino+avanco_da_rede,0:5]\n",
        "\n",
        "print(df_test)\n",
        "\n",
        "# print(df_test_orig)\n",
        "#periodo_aprendizado = df.iloc[indice_total_treino+avanco_da_rede-3,0]\n",
        "\n",
        "#Escala nas features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "df_train = sc.fit_transform(df_train)\n",
        "#Formação do x_train\n",
        "x_train = []\n",
        "y_train = []\n",
        "length = len(df_train)\n",
        "for i in range(timestamp, length):\n",
        "  x_train.append( df_train[i-timestamp:i,:])\n",
        "  y_train.append( df_train[i,features-1])\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(x_train[0])\n",
        "\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], timestamp, features))\n",
        "  \n",
        "# # ###Treinamento da rede neural\n",
        "model = None\n",
        "model = Sequential()\n",
        "# model.add(LSTM(units = 480, return_sequences = True, input_shape=( timestamp , features) ) ) \n",
        "model.add(LSTM(units = 480, return_sequences = False)) \n",
        "#model.add(Dropout(0.1))\n",
        "#model.add(Dense(units = 1)) \n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "#model.add(LSTM(50, input_shape=(44725, x_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "model.fit(x_train, y_train, epochs = epochs)\n",
        "#model.save('drive/My Drive/TCC/modelo/LSTM')\n",
        "#import tensorflow as tf\n",
        "#model = tf.keras.models.load_model('drive/My Drive/TCC/modelo/LSTM')\n",
        "#df_test_close = df_test_close.reshape(-1, 1)\n",
        "#df_test = sc.fit_transform(df_test)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc1 = MinMaxScaler()\n",
        "sc1.fit(df_train_orig.iloc[:,features-1].values.reshape(-1,1))\n",
        "df_test = sc.transform(df_test)\n",
        "x_test =    []\n",
        "y_test =    []\n",
        "y_max  =    []\n",
        "y_min  =    [] \n",
        "open_test = []\n",
        "data_test = []\n",
        "\n",
        "####Teste da rede neural##################\n",
        "\n",
        "#pegando maximos e minimos para testes com a previsao\n",
        "\n",
        "\n",
        "length = len(df_test)\n",
        "for i in range(timestamp, length):\n",
        "  x_test.append( df_test[i-timestamp:i,:])\n",
        "  y_test.append( df_test[i,features-1])\n",
        "  y_max.append( df_test_orig.iloc[i,3])\n",
        "  y_min.append( df_test_orig.iloc[i,2])\n",
        "  open_test.append( df_test_orig.iloc[i-1,4] )\n",
        "  data_test.append( df_test_orig.iloc[i,0])\n",
        "\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], timestamp, features))\n",
        "\n",
        "#Criando variavel Y_pred para receber as previsões\n",
        "y_pred = []\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "#Invertendo a escala para valores reais\n",
        "predicted_price = sc1.inverse_transform(y_pred)\n",
        "y_test = sc1.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "shift = y_test[0] - predicted_price[0]\n",
        "predicted_price = predicted_price + shift\n",
        "\n",
        "\n",
        "\n",
        "janela = len(predicted_price)\n",
        "\n",
        "previsao = pd.DataFrame(data=predicted_price , columns=['Previsão'])\n",
        "numero_real = pd.DataFrame(data=y_test , columns=['Fecahmaneto'])\n",
        "preco_de_abertura = pd.DataFrame(data=open_test , columns=['Abertura'])\n",
        "maxima = pd.DataFrame(data=y_max , columns=['Máxima'])\n",
        "minima = pd.DataFrame(data=y_min , columns=['Mínima'])\n",
        "# frames = [ preco_de_abertura, maxima, minima, numero_real, previsao,resumo_acumulado]\n",
        "# result = pd.concat(frames, axis=1, join='inner')\n",
        "data_test_pd =  pd.DataFrame(data=data_test , columns=['Data'])\n",
        "frames_to_csv= [ data_test_pd,maxima, minima, previsao]\n",
        "result_to_csv = pd.concat( frames_to_csv, axis=1, join='inner')\n",
        "\n",
        "result_to_csv.to_csv('previsoes_anuais.csv', mode='a', header=False,index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         open1    high1     low1   close1\n37293  1.20472  1.20386  1.20493  1.20416\n37294  1.20417  1.20278  1.20421  1.20305\n37295  1.20272  1.20265  1.20358  1.20315\n37296  1.20315  1.20315  1.20389  1.20370\n37297  1.20369  1.20328  1.20448  1.20425\n...        ...      ...      ...      ...\n43387  1.14482  1.14459  1.14657  1.14521\n43388  1.14520  1.14383  1.14585  1.14571\n43389  1.14571  1.14437  1.14571  1.14461\n43390  1.14461  1.14264  1.14485  1.14349\n43391  1.14349  1.14254  1.14524  1.14336\n\n[6099 rows x 4 columns]\n[[0.71779447 0.7189345  0.71210908 0.71769273 0.71620993]\n [0.71724004 0.71976606 0.71155704 0.71658347 0.71527911]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 372910 into shape (37291,2,4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2508284c6b8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# # ###Treinamento da rede neural\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 372910 into shape (37291,2,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Calculos  para previsao\n",
        "previsao = pd.DataFrame(data=predicted_price , columns=['Previsão'])\n",
        "numero_real = pd.DataFrame(data=y_test , columns=['Fecahmaneto'])\n",
        "#y_max_pd = pd.DataFrame(data=y_max, columns=['Máxima'])\n",
        "preco_de_abertura = pd.DataFrame(data=open_test , columns=['Abertura'])\n",
        "maxima = pd.DataFrame(data=y_max , columns=['Máxima'])\n",
        "minima = pd.DataFrame(data=y_min , columns=['Mínima'])\n",
        "frames = [ preco_de_abertura, maxima, minima, numero_real, previsao]\n",
        "result = pd.concat(frames, axis=1, join='inner')\n",
        "\n",
        "#Graficos de previsao\n",
        "plt.plot(y_test[:janela], color='red', label='Preço Atual das Ações')\n",
        "plt.plot(result.index.values[:janela], result.iloc[:janela,4].values , '.')\n",
        "plt.fill_between(result.index.values[:janela], result.iloc[:janela,1].values, result.iloc[:janela,2], alpha=0.5)\n",
        "plt.title('Previsão de Preço de Ações')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preço das Ações')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#####Calculo de acertos da previsao####################\n",
        "acumulador = 0\n",
        "lucro_prejuizo = []\n",
        "resumo_acumulado = []\n",
        "acertos = 0\n",
        "erros   = 0\n",
        "resumo  = []\n",
        "portcentagem = 0\n",
        "\n",
        "for i in range (0, janela):\n",
        "    soma = 0\n",
        "    if predicted_price[i] in pd.Interval(left=y_min[i], right=y_max[i]):\n",
        "      soma = abs( np.round(predicted_price[i],5) - np.around(open_test[i], 5 ))\n",
        "      soma = int(soma*100000)\n",
        "      acertos = acertos + 1\n",
        "    else:\n",
        "      if y_test[i] > open_test[i]:\n",
        "        if predicted_price[i] > open_test[i]:\n",
        "          soma = abs( np.round(y_test[i], 5) - np.round(open_test[i], 5) )\n",
        "          soma = int(soma*100000)\n",
        "          acertos = acertos + 1\n",
        "        else:\n",
        "          soma = np.round(open_test[i], 5) - np.round(y_test[i], 5)\n",
        "          soma = int(soma*100000)\n",
        "          erros = erros + 1\n",
        "      else:\n",
        "        if predicted_price[i] < open_test[i]:\n",
        "          soma = abs( np.round(y_test[i], 5) - np.round(open_test[i], 5))\n",
        "          soma = int(soma*100000)\n",
        "          acertos = acertos + 1\n",
        "        else:\n",
        "          soma = np.round(y_test[i], 5) - np.round(open_test[i], 5)\n",
        "          soma = int(soma*100000)\n",
        "          erros = erros + 1\n",
        "    acumulador = acumulador + soma\n",
        "    resumo_acumulado.append(acumulador)\n",
        "\n",
        "portcentagem = acertos*100/janela\n",
        "print(\"Acertos: \", acertos)\n",
        "print(\"Erros: \", erros)\n",
        "print(\"Pontos Ganhos: \", acumulador)\n",
        "print(\"%\", portcentagem)\n",
        "print(\"Meses em teste estudados: \", int(len(predicted_price)/janela))\n",
        "# resumo = pd.DataFrame(data=lucro_prejuizo , columns=['Resumo'])\n",
        "resumo_acumulado = pd.DataFrame(data=resumo_acumulado , columns=['Resumo Acumulado '])\n",
        "#return acumulador\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(resumo_acumulado, color='blue', label='Preço Atual das Ações')\n",
        "plt.title('Resumo Acumulado')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preço das Ações')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.title('Preço final')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preço das Ações')\n",
        "plt.plot(y_test, color='red', label='Preço Atual das Ações')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Mwki0cWZPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81e3c24e-9807-4eb8-96ad-f4a7624d3272"
      },
      "source": [
        "maior_ponto   =  0\n",
        "rotacao       =  0\n",
        "maior_acerto      =  0\n",
        "\n",
        "#for epochs in range(30,50):\n",
        "for i in range(1):\n",
        "   model = treinamento_rede_neural(timestamp, features, x_train, y_train, epochs)\n",
        "   pontos,acerto,data_test = teste_rede(model ,df_test, df_test_orig, sc, janela, shift )\n",
        "   if acerto > maior_acerto:\n",
        "     if pontos > maior_ponto:\n",
        "       #model.save('drive/My Drive/TCC/modelo/LSTM')\n",
        "       save_tocsv(data_test)\n",
        "       maior_ponto = pontos\n",
        "       maior_acerto = acerto\n",
        "\n",
        "print(maior_ponto, maior_acerto)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}